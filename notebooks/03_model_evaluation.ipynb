{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_model_evaluation.ipynb\n",
    "# -----------------------------------------------------------\n",
    "# Purpose: Train and evaluate machine learning models for credit risk scoring.\n",
    "# Steps:\n",
    "# 1. Load processed feature data\n",
    "# 2. Split data into training and test sets\n",
    "# 3. Train baseline Logistic Regression and XGBoost models\n",
    "# 4. Evaluate using accuracy, precision, recall, F1-score, and ROC-AUC\n",
    "# 5. Perform model explainability using SHAP\n",
    "# 6. Save the best model\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Import libraries\n",
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load Processed Data\n",
    "# ---------------------------\n",
    "\n",
    "def load_features(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the processed feature dataset.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the CSV file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "data_path: str = \"../data/processed/credit_data_features.csv\"\n",
    "df: pd.DataFrame = load_features(data_path)\n",
    "\n",
    "display(df.head())\n",
    "display(df.info())\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Define Features and Target\n",
    "# ---------------------------\n",
    "\n",
    "TARGET_COL: str = \"loan_status\"  # Adjust if your target column has a different name\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COL}' not found in dataset.\")\n",
    "\n",
    "X: pd.DataFrame = df.drop(columns=[TARGET_COL])\n",
    "y: pd.Series = df[TARGET_COL]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}, Test set size: {X_test.shape}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Model Training\n",
    "# ---------------------------\n",
    "\n",
    "def train_logistic_regression(X_train: pd.DataFrame, y_train: pd.Series) -> LogisticRegression:\n",
    "    \"\"\"\n",
    "    Train a logistic regression classifier.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target.\n",
    "    Returns:\n",
    "        LogisticRegression: Trained logistic regression model.\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_xgboost(X_train: pd.DataFrame, y_train: pd.Series) -> xgb.XGBClassifier:\n",
    "    \"\"\"\n",
    "    Train an XGBoost classifier.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        y_train (pd.Series): Training target.\n",
    "    Returns:\n",
    "        xgb.XGBClassifier: Trained XGBoost model.\n",
    "    \"\"\"\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "log_reg_model = train_logistic_regression(X_train, y_train)\n",
    "xgb_model = train_xgboost(X_train, y_train)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Evaluation\n",
    "# ---------------------------\n",
    "\n",
    "def evaluate_model(model, X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a model using common classification metrics.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model (sklearn or XGBoost).\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_test (pd.Series): True test labels.\n",
    "    Returns:\n",
    "        Dict[str, float]: Metrics including accuracy, precision, recall, F1, and AUC.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else np.nan\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "log_reg_metrics = evaluate_model(log_reg_model, X_test, y_test)\n",
    "xgb_metrics = evaluate_model(xgb_model, X_test, y_test)\n",
    "\n",
    "print(\"\\nLogistic Regression Metrics:\\n\", log_reg_metrics)\n",
    "print(\"\\nXGBoost Metrics:\\n\", xgb_metrics)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\")\n",
    "print(classification_report(y_test, log_reg_model.predict(X_test)))\n",
    "\n",
    "print(\"\\nXGBoost Classification Report:\\n\")\n",
    "print(classification_report(y_test, xgb_model.predict(X_test)))\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Model Explainability with SHAP\n",
    "# ---------------------------\n",
    "\n",
    "def explain_model_with_shap(model, X_sample: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Explain a model's predictions using SHAP values.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model (e.g., XGBoost).\n",
    "        X_sample (pd.DataFrame): Sample of data for SHAP explanation.\n",
    "    \"\"\"\n",
    "    explainer = shap.Explainer(model, X_sample)\n",
    "    shap_values = explainer(X_sample)\n",
    "\n",
    "    # Summary plot\n",
    "    shap.summary_plot(shap_values, X_sample, plot_type=\"bar\")\n",
    "    plt.show()\n",
    "\n",
    "# Run SHAP explanation for XGBoost (using a sample of test data)\n",
    "X_sample = X_test.sample(200, random_state=42)\n",
    "explain_model_with_shap(xgb_model, X_sample)\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Save Best Model\n",
    "# ---------------------------\n",
    "\n",
    "best_model = xgb_model if xgb_metrics['roc_auc'] > log_reg_metrics['roc_auc'] else log_reg_model\n",
    "model_path = \"../app/model.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"Best model saved at {model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
