{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_feature_engineering.ipynb\n",
    "# -----------------------------------------------------------\n",
    "# Purpose: Perform feature engineering on the cleaned dataset.\n",
    "# Steps:\n",
    "# 1. Load cleaned dataset\n",
    "# 2. Handle missing values and outliers\n",
    "# 3. Encode categorical variables\n",
    "# 4. Create domain-specific features (e.g., debt-to-income ratio, credit utilization)\n",
    "# 5. Scale numerical features\n",
    "# 6. Save processed dataset\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Import libraries\n",
    "from __future__ import annotations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from typing import Tuple\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Load Data\n",
    "# ---------------------------\n",
    "\n",
    "def load_cleaned_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load cleaned dataset from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the cleaned CSV file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded DataFrame.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "data_path: str = \"../data/processed/credit_data_cleaned.csv\"\n",
    "df: pd.DataFrame = load_cleaned_data(data_path)\n",
    "\n",
    "display(df.head())\n",
    "display(df.info())\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Handle Missing Values\n",
    "# ---------------------------\n",
    "\n",
    "def handle_missing_values(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fill missing values:\n",
    "      - Numeric columns: filled with median\n",
    "      - Categorical columns: filled with mode\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing values handled.\n",
    "    \"\"\"\n",
    "    for col in data.columns:\n",
    "        if data[col].isnull().sum() > 0:\n",
    "            if data[col].dtype in ['int64', 'float64']:\n",
    "                median_val = data[col].median()\n",
    "                data[col].fillna(median_val, inplace=True)\n",
    "            else:\n",
    "                mode_val = data[col].mode()[0]\n",
    "                data[col].fillna(mode_val, inplace=True)\n",
    "    return data\n",
    "\n",
    "df = handle_missing_values(df)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Handle Outliers\n",
    "# ---------------------------\n",
    "\n",
    "def remove_outliers_iqr(data: pd.DataFrame, columns: list[str], factor: float = 1.5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove outliers from numerical columns using the IQR method.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        columns (list[str]): Numerical columns to check for outliers.\n",
    "        factor (float): IQR multiplier for outlier detection.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with outliers removed.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
    "    return data\n",
    "\n",
    "numeric_cols: list[str] = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "df = remove_outliers_iqr(df, numeric_cols)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Feature Engineering\n",
    "# ---------------------------\n",
    "\n",
    "def create_domain_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create domain-specific features, such as:\n",
    "      - Debt-to-income ratio\n",
    "      - Credit utilization rate\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with new features added.\n",
    "    \"\"\"\n",
    "    # Example features: Adjust column names as needed based on dataset\n",
    "    if {'total_debt', 'annual_income'}.issubset(data.columns):\n",
    "        data['debt_to_income'] = data['total_debt'] / (data['annual_income'] + 1e-5)\n",
    "    \n",
    "    if {'current_balance', 'total_credit_limit'}.issubset(data.columns):\n",
    "        data['credit_utilization'] = data['current_balance'] / (data['total_credit_limit'] + 1e-5)\n",
    "    \n",
    "    return data\n",
    "\n",
    "df = create_domain_features(df)\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Encode Categorical Variables\n",
    "# ---------------------------\n",
    "\n",
    "def encode_categorical_features(data: pd.DataFrame, categorical_cols: list[str]) -> Tuple[pd.DataFrame, OneHotEncoder]:\n",
    "    \"\"\"\n",
    "    Encode categorical variables using OneHotEncoder.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        categorical_cols (list[str]): List of categorical columns.\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, OneHotEncoder]: Transformed DataFrame and fitted encoder.\n",
    "    \"\"\"\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "    encoded = encoder.fit_transform(data[categorical_cols])\n",
    "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "    \n",
    "    data = pd.concat([data.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "    return data, encoder\n",
    "\n",
    "categorical_cols: list[str] = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "df, ohe_encoder = encode_categorical_features(df, categorical_cols)\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Scale Numerical Features\n",
    "# ---------------------------\n",
    "\n",
    "def scale_features(data: pd.DataFrame, columns: list[str]) -> Tuple[pd.DataFrame, StandardScaler]:\n",
    "    \"\"\"\n",
    "    Scale numerical features using StandardScaler.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        columns (list[str]): Columns to scale.\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, StandardScaler]: Scaled DataFrame and fitted scaler.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    data[columns] = scaler.fit_transform(data[columns])\n",
    "    return data, scaler\n",
    "\n",
    "df, scaler = scale_features(df, numeric_cols)\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Save Processed Data\n",
    "# ---------------------------\n",
    "\n",
    "def save_processed_data(data: pd.DataFrame, filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Save processed DataFrame to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame to save.\n",
    "        filepath (str): Destination file path.\n",
    "    \"\"\"\n",
    "    data.to_csv(filepath, index=False)\n",
    "    print(f\"Processed feature data saved at {filepath}\")\n",
    "\n",
    "save_processed_data(df, \"../data/processed/credit_data_features.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
